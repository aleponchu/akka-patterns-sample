akka {
  loglevel = INFO
}

# Kamon Metrics
# ~~~~~~~~~~~~~~

kamon {

  environment {
    # Identifier for this service.
    service = "kamon-application"
  }

  # FQCN of the reporter instances that should be loaded when calling `Kamon.reporters.loadReportersFromConfig()`. All
  # reporter classes must have a default constructor. No metric filtering is applied to metric reporters started this way.

  # Example: `reporters = ["kamon.prometheus.PrometheusReporter", "kamon.zipkin.ZipkinReporter"]`.
  reporters = [ ]

  metric {

    # Time interval for collecting all metrics and send the snapshots to all subscribed actors.
    tick-interval = 10 seconds

    # When optimistic tick alignment is enabled the metrics ticker will try to schedule the ticks to happen as close as
    # possible to round tick-interval units. E.g. if the tick-interval is set to 60 seconds then Kamon will try to
    # schedule the ticks at the beginning of each minute; if the tick-interval is set to 20 seconds then Kamon will try
    # to schedule the ticks at 0, 20, and 40 seconds of each minute. The alignment is not meant to be perfect, just to
    # improve the ability to correlate the timestamp reported in ticks with logs.
    optimistic-tick-alignment = yes

    # Thread pool size used by the metrics refresh scheduler. This pool is only used to periodically sampling
    # range-sampler values.
    refresh-scheduler-pool-size = 2

  }

  trace {

    # Interval at which sampled finished spans will be flushed to SpanReporters.
    tick-interval = 10 seconds

    # Size of the internal queue where sampled spans will stay until they get flushed. If the queue becomes full then
    # sampled finished spans will be dropped in order to avoid consuming excessive amounts of memory. Each configured
    # reporter has a separate queue.
    reporter-queue-size = 4096
  }

  akka {
    # If ask-pattern-timeout-warning is enabled, a WARN level log message will be generated if a future generated by the `ask`
    # pattern fails with a `AskTimeoutException` and the log message will contain information depending of the strategy selected.
    # strategies:
    #   - off: nothing to do.
    #   - lightweight: logs the warning when a timeout is reached using org.aspectj.lang.reflect.SourceLocation.
    #   - heavyweight: logs the warning when a timeout is reached using a stack trace captured at the moment the future was created.
    ask-pattern-timeout-warning = off

    # Filter names from which actor groups will be created. Setting up actor groups require two steps: first, define
    # a filter under the kamon.util.filters key and second, add that filter to this key. E.g.: for the following config:
    #
    # kamon.util.filters {
    #   worker-actors {
    #     includes = ["my-system/user/application/worker-*", "my-system/user/workers/**"]
    #     excludes = [ ]
    #   }
    # }
    #
    # kamon.akka {
    #   actor-groups = [ "worker-actors" ]
    # }
    #
    # An actor group named "worker-actors" will be created and include all the actors whose path matches the provided
    # patterns.
    actor-groups = [ ]
  }

  util {
    filters {
      "akka.tracked-actor" {
        includes = []
        excludes = ["*/system/**", "*/user/IO-**"]
      }

      "akka.tracked-router" {
        includes = []
        excludes = []
      }

      "akka.tracked-dispatcher" {
        includes = []
        excludes = []
      }

      "akka.traced-actor" {
        includes = []
        excludes = []
      }
    }
  }

  # Controls whether the AspectJ Weaver missing warning should be displayed if any Kamon module requiring AspectJ is
  # found in the classpath but the application is started without the AspectJ Weaver.
  show-aspectj-missing-warning = yes

  statsd {

    # Hostname and port in which your StatsD is running. Remember that StatsD packets are sent using UDP and
    # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
    hostname = "127.0.0.1"
    port = 8125

    # All time values are collected in nanoseconds,
    # to scale before sending to statsd set "time-units" to "s" or "ms" or "Âµs".
    # Value "n" is equivalent to omitting the setting
    time-unit = "ms"

    # All memory values are collected in bytes,
    # to scale before sending to statsd set "memory-units" to "gb" or "mb" or "kb".
    # Value "b" is equivalent to omitting the setting
    information-unit = "b"

    # FQCN of the implementation of `kamon.statsd.MetricKeyGenerator` to be instantiated and used for assigning
    # metric names. The implementation must have a single parameter constructor accepting a `com.typesafe.config.Config`.
    metric-key-generator = kamon.statsd.SimpleMetricKeyGenerator

    simple-metric-key-generator {

      # Application prefix for all metrics pushed to StatsD. The default namespacing scheme for metrics follows
      # this pattern:
      #    application.host.entity.entity-name.metric-name
      # application = "yourapp"

      # Includes the name of the hostname in the generated metric. When set to false, the scheme for the metrics
      # will look as follows:
      #    application.entity.entity-name.metric-name
      include-hostname = true

      # Allow users to override the name of the hostname reported by kamon. When changed, the scheme for the metrics
      # will have the following pattern:
      #   application.hostname-override-value.entity.entity-name.metric-name
      # hostname-override = none

      # When the sections that make up the metric names have special characters like dots (very common in dispatcher
      # names) or forward slashes (all actor metrics) we need to sanitize those values before sending them to StatsD
      # with one of the following strategies:
      #   - normalize: changes ': ' to '-' and ' ', '/' and '.' to '_'.
      #   - percent-encode: percent encode the section on the metric name. Please note that StatsD doesn't support
      #     percent encoded metric names, this option is only useful if using our docker image which has a patched
      #     version of StatsD or if you are running your own, customized version of StatsD that supports this.
      metric-name-normalization-strategy = normalize
    }
  }

    # modules can be disabled at startup using yes/no arguments.
  modules {
    kamon-log-reporter.auto-start = yes
    kamon-system-metrics.auto-start = yes
    kamon-akka {
      requires-aspectj = yes
    }
  }

}


#######################################
# spray-routing Reference Config File #
#######################################

# This is the reference config file that contains all the default settings.
# Make your edits/overrides in your application.conf.

spray.routing {

  # Enables/disables the returning of more detailed error messages to the
  # client in the error response
  # Should be disabled for browser-facing APIs due to the risk of XSS attacks
  # and (probably) enabled for internal or non-browser APIs
  # (Note that spray will always produce log messages containing the full error details)
  verbose-error-messages = off

  # the minimal file size triggering file content streaming
  # set to zero to disable automatic file-chunking in the FileAndResourceDirectives
  file-chunking-threshold-size = 128k

  # the size of an individual chunk when streaming file content
  file-chunking-chunk-size = 128k

  # Enables/disables ETag and `If-Modified-Since` support for FileAndResourceDirectives
  file-get-conditional = on

  # Enables/disables the rendering of the "rendered by" footer in directory listings
  render-vanity-footer = yes

  # a config section holding plain-text user/password entries
  # for the default FromConfigUserPassAuthenticator
  users {
    # bob = secret
  }

  # the maximum size between two requested ranges.
  # Ranges with less space in between will be coalesced.
  range-coalescing-threshold = 80

  # the maximum number of allowed ranges per request.
  # Requests with more ranges will be rejected due to DOS suspicion.
  range-count-limit = 16
}

#######################################
# Akka                                #
#######################################


#######################################
# Dispatchers #
#######################################

city-weather-dispatcher {

  type = "Dispatcher"
  executor = "fork-join-executor"

  thread-pool-executor {
    core-pool-size-min = 1
    # No of core threads ... ceil(available processors * factor)
    core-pool-size-factor = 2.0
    core-pool-size-max = 4
  }

  # This will be used if you have set "executor = "fork-join-executor""
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 2

    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 2.0

    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 4
  }

  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 1
}


db-dispatcher {
  type = "Dispatcher"
  executor = "fork-join-executor"

  # This will be used if you have set "executor = "fork-join-executor""
  fork-join-executor {
    # Min number of threads to cap factor-based parallelism number to
    parallelism-min = 2

    # Parallelism (threads) ... ceil(available processors * factor)
    parallelism-factor = 2

    # Max number of threads to cap factor-based parallelism number to
    parallelism-max = 10
  }
  # Throughput defines the maximum number of messages to be
  # processed per actor before the thread jumps to the next actor.
  # Set to 1 for as fair as possible.
  throughput = 1

}
